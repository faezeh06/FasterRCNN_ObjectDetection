# -*- coding: utf-8 -*-
"""FasterRCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19864DFA1MZmI7jCMk3TzmaIIwYIDPSqB
"""

# =============================================================================
# Import required libraries
# =============================================================================
import torch
import torchvision
from torchvision.transforms import functional as F
import numpy as np
import pandas as pd
import os
import math
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches


# =============================================================================
# Check if CUDA is available
# =============================================================================
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# clone Dataset from Github
!git clone https://github.com/experiencor/raccoon_dataset



class RaccoonDataset(torch.utils.data.Dataset):
  def __init__(self, root, phase):
    self.root = root
    self.phase = phase
    self.targets = pd.read_csv(os.path.join(root, 'data/{}_labels.csv'.format(phase)))
    self.imgs = self.targets['filename']

  def __getitem__(self, idx):
    img_path = os.path.join(self.root, 'images', self.imgs[idx])
    img = Image.open(img_path).convert('RGB')
    img = F.to_tensor(img)
    box_list = self.targets[self.targets['filename'] == self.imgs[idx]]
    box_list = box_list[['xmin', 'ymin', 'xmax', 'ymax']].values
    boxes = torch.tensor(box_list, dtype=torch.float32)
    labels = torch.ones((len(box_list), ), dtype=torch.int64)

    target = {}
    target['boxes'] = boxes
    target['labels'] = labels
    return img, target

  def __len__(self):
    return len(self.imgs)

# split Dataset train & test
train_dataset = RaccoonDataset('./raccoon_dataset/', 'train')
test_dataset = RaccoonDataset('./raccoon_dataset/', 'test')

def new_concat(batch):
  return tuple(zip(*batch))

# =============================================================================
# DataLoader
# =============================================================================

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=new_concat)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=new_concat)

# =============================================================================
# CNN models
# =============================================================================
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(1024, 2)
model.to(device)


# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

# =============================================================================
# training
# =============================================================================
num_epochs = 100
def train_one_epoch(model, optimizer, train_dataloader):
    model.train()
    total_loss = 0
    for imgs, targets in train_dataloader:
        imgs = [image.to(device) for image in imgs]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        loss_dict = model(imgs, targets)
        losses = sum(loss for loss in loss_dict.values())
        total_loss += losses
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()
    return total_loss/len(train_dataloader)
for epoch in range(num_epochs):
    loss = train_one_epoch(model, optimizer, train_loader)
    print('epoch [{}]:  \t lr: {}  \t loss: {}  '.format(epoch, lr_scheduler.get_last_lr(), loss))
    lr_scheduler.step()

# =============================================================================
# evaluate
# =============================================================================

def evaluate(model, test_dataloader):
    model.eval()
    with torch.no_grad():
        cnt = 0
        for images , targets in test_dataloader:
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            out = model(images)
            scores = out[0]['scores'].cpu().numpy()
            inds = scores > 0.7
            bxs = out[0]['boxes'].cpu().numpy()
            bxs = bxs[inds]
            gt = targets[0]['boxes'].cpu().numpy()
            img = images[0].permute(1, 2, 0).cpu().numpy()
            #----------------------------------------------------------
            fig, ax = plt.subplots(1)
            ax.imshow(img)
            for j in range(len(gt)):
                rect1 = patches.Rectangle((int(gt[j][0]),int(gt[j][1])),abs(gt[j][0]-gt[j][2]),
                                abs(gt[j][1]-gt[j][3]),linewidth=3,edgecolor='g',facecolor='none')
                ax.add_patch(rect1)
            for i in range(len(bxs)):
                rect = patches.Rectangle((int(bxs[i][0]),int(bxs[i][1])),abs(bxs[i][0]-bxs[i][2]),
                                         abs(bxs[i][1]-bxs[i][3]),linewidth=3,edgecolor='r',facecolor='none')
                ax.add_patch(rect)
            fig.savefig("/content/output_images/{}.png".format(cnt), dpi=90, bbox_inches='tight')
            cnt = cnt + 1

evaluate(model, test_loader)